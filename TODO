OK add configuration scheduler in name of config .sh

OK configurable via sbatchman init and asked at installation

OK add to sbatchman configure option to pass modules to be loaded

# SBatchman commands
configure
  file or parameters
launch (runs a job if there does not exist a combination (hostname, config, tag, command) in experiments directory or if status is FAILED, TIMEOUT, CANCELLED)
  file (+ whitelist/blacklist) or parameters
archive
  by tag/config/hostname
update-jobs
  update status of all jobs in experiments directory
  query scheduler for status of all jobs
init
  creates global SbatchMan configuration file (hostname, scheduler)
status
  user interface

# API
get_jobs(name: str, archive: False) -> List[Job]
get_jobs_dataframe() -> pd.DataFrame
parse_command(command: str) -> Dict[str, Any]
create_config(name: str, scheduler: str, **kwargs) -> None
launch_job(hostname: str, name: str, tag: str, config: str, command: str, archive_name: str = None) -> None

Job class
 - status
 - timestamp
 - scheduler
 - hostname
 - tag
 - archive_name
 - status -> Status
 - config -> Config

Config class
 - name
 - scheduler
 - env variables
 - custom parameters of each scheduler

Status enum
 - PENDING
 - RUNNING
 - COMPLETED
 - FAILED
 - CANCELLED
 - UNKNOWN

.filter(lamda x: x.hostname = 'hostname' and x.tag = 'smallGraph' and archive_name = '1')[0].get_stdout() -> String
.filter(lamda x: x.hostname = 'hostname')[0].get_stderr() -> String


add command to update the status of all jobs, that queries the specific scheduler


#### generated by sbatchman
#### do not edit it manually, use sbatchman configure --file config.yaml to add configurations
baldo:
  scheduler: slurm
  configs:
    bfs1cpu:
      partition: short
      cpu: 1
      ...
    bfs2cpu:
      partition: long
      cpu: 2
      ...
hpc-unitn:
  scheduler: pbs
  default_conf:
      partition: unitn-short
      ...
  configs:
    bfs1cpu:
      cpu: 1
      <!-- default queue: unitn-short -->
      ...
    bfs2cpu:
      partition: long
      cpu: 2
      ...

# Example
sbatchman configure --file config.yaml

sbatchman configure slurm --name cpu1 --hostname baldo --partition short --cpu 1
sbatchman configure slurm --name cpu2 --hostname baldo --partition short --cpu 2
sbatchman configure pbs --name cpu1 --hostname hpc-unitn --partition unitn-short --cpu 1


# Archive utility for sbatchman
sbatchman archive --hostname baldo --experiment bfs1cpu --tag shortDiam --archive_name run1

All parameters optional

Experiments directory structure:
experiments/
├── baldo
│   ├── bfs1cpu
│   │   ├── shortDiam
│   │   │   ├── job_id
│   │   │   ├── job_id
│   │   ├── largeDiam
│   │   │   ├── job_id
│   │   │   ├── job_id
│   ├── bfs2cpu
│   │   ├── tag1
│   │   │   ├── job_id
│   │   │   ├── job_id
│   │   ├── tag2
│   │   │   ├── job_id
│   │   │   ├── job_id
archive/
|── archive_name
|   |── baldo
|   |   ├── bfs1cpu
|   |   │   ├── shortDiam
|   |   │   │   ├── job_id
|   |   │   │   ├── job_id
|   |   ├── bfs2cpu


# launch jobs
sbatchman launch --hostname baldo --name bfs1cpu --tag shortDiam --config bfs1cpu --command "python script.py" --archive_name run1

sbatchman launch -f config.yaml --exclude_tag shortDiam --include_config bfs1cpu,bfs2cpu

variables:
  merged: [True, False]
  atomics: [True, False]
  atomics: [True, False]
  scale: scales.txt
command: python script.py --file {dataset} --n {n} --m {m}
experiments:
  bfs_{scale}_cpu:
    command: python script.py --file {dataset} --n {n} --m {m}
    tags:
      shortDiam:
        variables:
          dataset: datasets/small
      largeDiam:
        variables:
          dataset: datasets/large
      atomics:
        command: python script.py --file {small_dim} --n {n} --m {m} --atomic